{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install xlsxwriter      # writing excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PREPARATION OF DATASETS FOR THE MODEL\n",
    "\n",
    "### RELATIVE_PROTEOMICS.TXT\n",
    "# I created the datasets using Excel and then just saved necessary columns for different conditions.\n",
    "# 1. I copied in a new excel sheet from MaxQuant excel output \"proteinGroups\" uniprot IDs, Gene names, molecular weight, and intensities.\n",
    "# 2. Calculated molar abundances of each protein in the dataset using total protein content and mean average of intensities per condition per sample.\n",
    "\n",
    "# Note! the f factor for enhanceGEM pipeline doesn't change with different Ptot for the same proteomics dataset.\n",
    "# It is a proportionality coefficient that is used with the provided Ptot (in getModelParameters) for constraining pool.\n",
    "\n",
    "# 3. Saved output using following lines:\n",
    "df1=pd.read_excel(\"proteins_rhto_v02.xlsx\", sheet_name='proteomics', usecols='B,AH') # B corresponds to Gene names, other column represents molar abundances\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['mmol_gDCW_average'] = df1['mmol_gDCW_average'].replace(np.nan, 0)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('relative_proteomics.txt', sep='\\t', index=False)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ABS_PROTEOMICS.TXT\n",
    "\n",
    "# Followed the same guidelines as for relative_proteomics.txt, the only difference being that here all replicates per condition have to be included.\n",
    "# It is because GECKO includes the filtering of absolute proteomics measurements.\n",
    "\n",
    "# Saved output:\n",
    "df2=pd.read_excel(\"proteins_rhto_v02.xlsx\", sheet_name='proteomics', usecols='A,B,CO,CP')\n",
    "df2.to_csv('abs_proteomics.txt', sep='\\t', index=False)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FERMENTATIONDATA.TXT: to constrain the model(s) during generate_protModels pipeline\n",
    "#df=pd.read_csv(\"fermentationData.txt\", sep='\\t')\n",
    "df3=pd.read_excel(\"proteins_rhto_v02.xlsx\", sheet_name='fermentationData', skiprows=[0,1,2,4,6,7,8], usecols='A,B,C,D,E,F,G')\n",
    "df3.to_csv('fermentationData.txt', sep='\\t', index=False)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHEMOSTATDATA.TSV: to fit growth-associated maintenance (GAM) during generate_protModels pipeline\n",
    "#df=pd.read_csv('chemostatData.tsv',sep='\\t')\n",
    "#manually edit the file usign excel\n",
    "df4=pd.read_excel('proteins_rhto_v02.xlsx', sheet_name=\"chemostatData\", skiprows=[0,1,2,6,7,8])\n",
    "df4.to_csv('chemostatData.tsv', sep='\\t', index=False)\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### selectedAnnotation\n",
    "#df5=pd.read_excel(\"proteins_rhto.xlsx\", sheet_name='selectedAnnotation', usecols='A,D')\n",
    "df5=pd.read_excel(\"proteins_rhto.xlsx\", sheet_name='selectedAnnotation')\n",
    "df5.to_csv('selectedAnnotation.txt', sep='\\t', index=False)\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df55=pd.read_excel(\"proteins_rhto.xlsx\", sheet_name='uniprot_swissprot_full_10k', usecols='A,C')\n",
    "df55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=pd.merge(df5, df55, on='uniprot')\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ribosome\n",
    "#df1=pd.read_excel(\"proteins_rhto.xlsx\", sheet_name='ribosomal_2', usecols='A,C,D')\n",
    "#df2=pd.read_excel(\"ribosome_full.xlsx\", sheet_name='Sheet1', usecols='A,E,F,G')\n",
    "#output=pd.merge(df1, df2, on='Entry')\n",
    "output=pd.read_excel(\"proteins_rhto.xlsx\", sheet_name='ribosome')\n",
    "output.to_csv('ribosome.txt', sep='\\t', index=False)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### UNIPROT.TAB: to assign enzymatic constraints during the enhanceGEM pipeline\n",
    "## 2.Generate a new, corrected uniprot.tab file with more ec numbers to increase the coverage of enzymes in ecModel\n",
    "# 2.1.Create excel file from old uniprot.tab file\n",
    "df6=pd.read_csv(\"uniprot_original.tab\", sep='\\t')\n",
    "# 2.2.Manually combine in excel ec numbers from rhtoModel with ec numbers from uniprot.tab, based on gene association\n",
    "# 2.3.Create new uniprot file:\n",
    "df6=pd.read_excel(\"uniprot_rhto_corrected.xlsx\", sheet_name='uniprot_manually_with_new_ec')\n",
    "df6.to_csv('uniprot.tab', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_excel(\"uniprot_rhto_corrected.xlsx\", sheet_name='uniprot_original', usecols='A,B,C,D,E')\n",
    "df2=pd.read_excel(\"uniprot_rhto_corrected.xlsx\", sheet_name='new_with_ec')\n",
    "df2.to_csv('uniprot_new_EC.tab', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PROTEINS.TXT: protein pool in geckopy               # not used, as geckopy offers only proteomics integration\n",
    "# 1.1.Prepare datasets:\n",
    "# a) protein IDs, proteomics measurements in intensities;\n",
    "# b) uniprot file with protein IDs and molecular weights for R.toruloides\n",
    "# 1.2.Merge based on protein IDs for mw and abundance\n",
    "df1=pd.read_excel(\"proteins_rhto.xlsx\", sheet_name='intensities_to_fractions', usecols='A,D')\n",
    "df2=pd.read_excel(\"proteins_rhto.xlsx\", sheet_name='uniprot_mws_g_mol')\n",
    "proteins_fractions=pd.merge(df1, df2[['uniprot', 'mw']], on='uniprot')\n",
    "# 1.3.Create excel sheet \"proteins_fractions\", using code below (xlsxwriter)\n",
    "df=pd.read_excel(\"proteins_rhto.xlsx\", sheet_name='proteins_fractions', usecols='A,B,C')\n",
    "df.to_csv('proteins.txt',index=False)\n",
    "# 1.4.Move proteins.txt to geckopy/data_files of your computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OTHERS\n",
    "df1=pd.read_csv(\"manual_data.txt\", sep='\\t')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#F-factor calculations:\n",
    "df1=pd.read_excel(\"rhto_f_factor.xlsx\", sheet_name='f_factor_ecModelP', usecols='J')\n",
    "df2=pd.read_excel(\"rhto_f_factor.xlsx\", sheet_name='f_factor_ecModelP_calculations', usecols='A,E')\n",
    "f_factor=pd.merge(df1, df2[['uniprotID', 'REF_048_g/gDW_mean']], on='uniprotID')\n",
    "f_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprot = pd.read_csv(\"uniprot.tab\", sep='\\t')\n",
    "uniprot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many enzymatic proteins are covered by proteomics dataset?\n",
    "df1=pd.read_excel(\"proteins_rhto.xlsx\", sheet_name='uniprot_full_10k', usecols='A')\n",
    "df2=pd.read_excel(\"proteins_rhto.xlsx\", sheet_name='proteomics_mmol_gDW', usecols='A')\n",
    "output=pd.merge(df1, df2)\n",
    "output\n",
    "# No, it doesn't work like that because uniprot contains all proteins, and sorting according to ec numbers also not possible, because many lack them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many enzymatic proteins were filtered out to make v5 ecModelP?\n",
    "df1=pd.read_excel(\"proteins_rhto.xlsx\", sheet_name='abs_proteomics_calculations', usecols='A,B,AZ,BA,BB')\n",
    "df2=pd.read_excel(\"proteins_rhto.xlsx\", sheet_name='v5_pool_match')\n",
    "output=pd.merge(df1, df2, on='uniprotID')\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter('output.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Convert the dataframe to an XlsxWriter Excel object.\n",
    "output.to_excel(writer, sheet_name='Sheet1', index=None)\n",
    "\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### RESULT PREPARATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save result files for escher\n",
    "df1=pd.read_excel(\"results_rhto.xlsx\", sheet_name='fluxes', usecols='AG,AH')\n",
    "df1.to_csv('fluxes_XNlim.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1=pd.read_excel(\"results_rhto.xlsx\", sheet_name='enzUsage', usecols='AX,AY')\n",
    "df1.to_csv('capUse_XNlim.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign selected annotation to enzyme usage reports\n",
    "#df1=pd.read_excel(\"results_rhto.xlsx\", sheet_name='assign_enzNames')\n",
    "#df2=pd.read_excel(\"enzUsage.xlsx\", sheet_name='Xexp_cobra')\n",
    "#output=pd.concat([df1, df2], axis=1)\n",
    "#output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign enzyme names to usage reports\n",
    "df1=pd.read_excel(\"results_rhto.xlsx\", sheet_name='assign_enzNames')\n",
    "df2=pd.read_excel(\"proteins_rhto.xlsx\", sheet_name='uniprot_swissprot_full_10k', usecols='A,B')\n",
    "output=pd.merge(df1, df2, on='uniprot')\n",
    "output\n",
    "#output.to_csv('capUsage_annotated.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
